{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "################################# initial ########################################\n",
    "face_size = 30\n",
    "################################# Path ########################################\n",
    "face_cascade = cv2.CascadeClassifier('/Users/jack_wu/opencv/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('/Users/jack_wu/opencv/data/haarcascades/haarcascade_eye.xml')\n",
    "#img = cv2.imread('/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/FinalProject_dataset/adult/female/183.jpg')\n",
    "#img = cv2.imread('0.JPG')\n",
    "\n",
    "\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "# for (x,y,w,h) in faces:\n",
    "#     cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#     roi_gray = gray[y:y+h, x:x+w]\n",
    "#     roi_color = img[y:y+h, x:x+w]\n",
    "#     eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#     for (ex,ey,ew,eh) in eyes:\n",
    "#         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initial_face(item_Num, age, gender):\n",
    "\ts_jpg='.jpg'\n",
    "\tcount = 0\n",
    "\tinput_address = \"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/FinalProject_dataset/\"+age+'/'+gender+'/'\n",
    "\toutput_address = \"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Face_detection/\"+age+'/'+gender+'/'\n",
    "\tfor file_count in range(item_Num):\n",
    "\t\ts_file_count = str(file_count)\n",
    "\t\timg = cv2.imread(input_address + s_file_count + s_jpg)\n",
    "\t\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\t\n",
    "\t\tif (len(faces)!=0):\n",
    "\t\t\tfor (x,y,w,h) in faces:\n",
    "\t\t\t\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t\tcv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\t\t\t\troi_gray = gray[y:y+h, x:x+w]\n",
    "\t\t\t\tresize_face=cv2.resize(roi_gray,(30,30),interpolation=cv2.INTER_AREA)\n",
    "\t\t\t\tcv2.imwrite(output_address+str(count)+s_jpg, resize_face, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "\t\t\t\tcount = count + 1\n",
    "\t\telse:\n",
    "\t\t\t## No face detect\n",
    "\t\t\tpass\n",
    "\treturn count\n",
    "\n",
    "def horizonal_filpping(item_Num, age, gender): #item_Num = count\n",
    "\ts_jpg='.jpg'\n",
    "\tcount = 0\n",
    "\tinput_address = \"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Face_detection/\"+age+'/'+gender+'/'\n",
    "\toutput_address = \"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Face_detection/\"+age+'/'+gender+'/'\n",
    "\tfor file_count in range(item_Num):\n",
    "\t\ts_file_count = str(file_count)\n",
    "\t\timg = cv2.imread(input_address + s_file_count + s_jpg)\n",
    "\t\tfilp_img = cv2.flip( img, 1)\n",
    "\t\tcv2.imwrite(output_address+str(item_Num+count)+s_jpg, filp_img, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "\t\tcount = count +1\n",
    "\treturn count\n",
    "\n",
    "def img2csv (age, gender):\n",
    "\tbmpfile=glob.glob(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Face_detection/\"+age+'/'+gender+'/'+'*.jpg')\n",
    "\tX_train = []\n",
    "\tfor bmp_dir in bmpfile:\n",
    "\t\timg = cv2.imread(bmp_dir,0)\n",
    "\t\tflatten_img = np.array(img).flatten() # a = np.array([1,2],[3,4]) , a.T.flatten [1,3,2,4] , a.flatten [1,2,3,4]\n",
    "\t\t#X_train = np.append(X_train, flatten_img, axis = 0)\n",
    "\t\tX_train.append(flatten_img)\n",
    "\tX_train = np.array(X_train)\n",
    "\tnp.savetxt(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Face_detection/\"+age+'_'+gender+\".csv\", X_train, delimiter=',')\n",
    "\treturn X_train\n",
    "\n",
    "def merge_train_data():\n",
    "\ttry:\n",
    "\t\tos.remove(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/X_train.csv\")\n",
    "\texcept OSError:\n",
    "\t\tpass\n",
    "\tcsvs=glob.glob('/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Face_detection/*.csv')\n",
    "\ttrain_data = open(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/X_train.csv\",\"a\")\n",
    "\tlable_data = open(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Y_train.csv\",\"w\")\n",
    "\tcount = 0\n",
    "\tY_train = 0\n",
    "\tfor csv_file in csvs:\n",
    "\t\tf = open(csv_file)\n",
    "\t\tfor line in f:\n",
    "\t\t\tY_train += 1\n",
    "\t\t\ttrain_data.write(line)\n",
    "\t\t\tlable_data.write(str(count))\n",
    "\t\t\tlable_data.write('\\n')\n",
    "\t\tcount +=1\n",
    "\t\tf.close()\n",
    "\ttrain_data.close()\n",
    "\tlable_data.close()\n",
    "\t#return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#res=cv2.resize(face,(30,30),interpolation=cv2.INTER_CUBIC)\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)\n",
    "\n",
    "# adult_female_count = initial_face(1210,'adult','female')\n",
    "# flip_img = horizonal_filpping(adult_female_count,'adult','female')\n",
    "# X_train_shape=img2csv ('adult','female')\n",
    "# print (\"Train size of adult_female\",X_train_shape)\n",
    "\n",
    "# adult_male_count = initial_face(1588,'adult','male')\n",
    "# flip_img = horizonal_filpping(adult_male_count,'adult','male')\n",
    "# X_train_shape=img2csv ('adult','male')\n",
    "# print (\"Train size of adult_male\",X_train_shape)\n",
    "\n",
    "# child_female_count = initial_face(774,'child','female')\n",
    "# flip_img = horizonal_filpping(child_female_count,'child','female')\n",
    "# X_train_shape=img2csv ('child','female')\n",
    "# print (\"Train size of child_female\",X_train_shape)\n",
    "\n",
    "# child_male_count = initial_face(650,'child','male')\n",
    "# flip_img = horizonal_filpping(child_male_count,'child','male')\n",
    "# X_train_shape=img2csv ('child','male')\n",
    "# print (\"Train size of child_male\",X_train_shape)\n",
    "\n",
    "# elder_female_count = initial_face(452,'elder','female')\n",
    "# flip_img = horizonal_filpping(elder_female_count,'elder','female')\n",
    "# X_train_shape=img2csv ('elder','female')\n",
    "# print (\"Train size of elder_female\",X_train_shape)\n",
    "\n",
    "# elder_male_count = initial_face(878,'elder','male')\n",
    "# flip_img = horizonal_filpping(elder_male_count,'elder','male')\n",
    "# X_train_shape=img2csv ('elder','male')\n",
    "# print (\"Train size of elder_male\",X_train_shape)\n",
    "\n",
    "# young_female_count = initial_face(1002,'young','female')\n",
    "# flip_img = horizonal_filpping(young_female_count,'young','female')\n",
    "# X_train_shape=img2csv ('young','female')\n",
    "# print (\"Train size of young_female\",X_train_shape)\n",
    "\n",
    "# young_male_count = initial_face(830,'young','male')\n",
    "# flip_img = horizonal_filpping(young_male_count,'young','male')\n",
    "# X_train_shape=img2csv ('young','male')\n",
    "# print (\"Train size of young_male\",X_train_shape)\n",
    "\n",
    "\n",
    "\n",
    "#adult-> female, num_pic = 1210, effective_pic = 1069\n",
    "#adult-> male, num_pic = 1588, effective_pic = 1268\n",
    "#child-> female, num_pic = 774, effective_pic = 626\n",
    "#child-> male, num_pic = 650, effective_pic = 510\n",
    "#elder-> female, num_pic = 452, effective_pic = 351\n",
    "#elder-> male, num_pic = 878, effective_pic = 649\n",
    "#young-> female, num_pic = 1002, effective_pic = 729\n",
    "#young-> male, num_pic = 830, effective_pic = 670\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merge_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6e40d02d1194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtest_lable_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmerge_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mmerge_testing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merge_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "import csv\n",
    "import random\n",
    "def merge_testing_data(percentage):\n",
    "\n",
    "\t#train_data = open(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/X_train.csv\",\"r\")\n",
    "\t#lable_data = open(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Y_train.csv\",\"r\")\n",
    "\t\n",
    "\ttrain_data = genfromtxt(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/X_train.csv\",delimiter=',')\n",
    "\tlable_data = genfromtxt(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Y_train.csv\",delimiter=',')\n",
    "\t\n",
    "\tnum_testing = len(train_data) * percentage // 100\n",
    "\tindicies = random.sample(range(len(train_data)), num_testing)\n",
    "\t\n",
    "\t#f2=open(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/hw2/final/d_w_total.csv\",'w')\n",
    "\t#w_file2=csv.writer(f2)\n",
    "\t#w_file2.writerows(w_total)\n",
    "\n",
    "\twith open(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/X_testing.csv\",'w') as X_testing:\n",
    "\t\tfor i in indicies:\n",
    "\t\t\ttest_data = csv.writer(X_testing, dialect='excel')\n",
    "\t\t\ttest_data.writerow(train_data[i])\n",
    "\t\t\t\n",
    "\ttest_lable_data = open(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Y_testing.csv\",\"w\")\n",
    "\tfor i in indicies:\n",
    "\t\ttest_lable_data.write(str(lable_data[i]))\n",
    "\t\ttest_lable_data.write('\\n')\n",
    "\n",
    "\ttest_lable_data.close()\n",
    "\n",
    "merge_train_data()\n",
    "merge_testing_data(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train (15105, 900)\n",
      "Y_train (15105, 8)\n",
      "X_test (3021, 900)\n",
      "Y_test (3021, 8)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from numpy import genfromtxt\n",
    "\n",
    "X_train = genfromtxt(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/X_train.csv\",delimiter=',')\n",
    "Y_train = genfromtxt(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Y_train.csv\",delimiter=',')\n",
    "\n",
    "X_test = genfromtxt(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/X_testing.csv\",delimiter=',')\n",
    "Y_test = genfromtxt(\"/Users/jack_wu/Documents/Machine learing/Lecture/ML/final/Y_testing.csv\",delimiter=',')\n",
    "# X_train = np.array(X_train)\n",
    "# Y_train = np.array(Y_train)\n",
    "#X_train = X_train.reshape(X_train.shape[0], -1) / 255.   # normalize\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes=8)\n",
    "\n",
    "#X_test = X_test.reshape(X_test.shape[0], -1) / 255.   # normalize\n",
    "Y_test = np_utils.to_categorical(Y_test, num_classes=8)\n",
    "\n",
    "print (\"X train\",X_train.shape)\n",
    "print (\"Y_train\",Y_train.shape)\n",
    "print (\"X_test\",X_test.shape)\n",
    "print (\"Y_test\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2c02b09a97bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX_train_3030\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_test_3030\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "np.random.seed(1337)\n",
    "X_train_3030 = np.zeros((X_train.shape[0],face_size,face_size))\n",
    "X_test_3030 = np.zeros((X_test.shape[0],face_size,face_size))\n",
    "for train in range(X_train.shape[0]):\n",
    "\tX_train_3030[train,:,:] = np.reshape(X_train[1,:],(30,30))\n",
    "for train in range(X_test.shape[0]):\n",
    "\tX_test_3030[train,:,:] = np.reshape(X_test[1,:],(30,30))\n",
    "X_train = X_train_3030\n",
    "\n",
    "X_test = X_test_3030\n",
    "\n",
    "print (X_train.shape)\n",
    "print (Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Epoch 1/1\n",
      "15104/15105 [============================>.] - ETA: 0s - loss: 13.1026 - acc: 0.1757"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 1, 30, 30) for Tensor 'conv2d_1_input:0', which has shape '(64, 1, 30, 30)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e06653384649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training ------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Another way to train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTesting ------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    962\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 1, 30, 30) for Tensor 'conv2d_1_input:0', which has shape '(64, 1, 30, 30)'"
     ]
    }
   ],
   "source": [
    "# img_rows = img_cols = face_size\n",
    "# X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "# X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "# input_shape = (1, img_rows, img_cols)\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# # Conv layer 1 output shape (32, 28, 28)\n",
    "# model.add(Convolution2D(\n",
    "#     batch_input_shape=(64, 1, 30, 30),\n",
    "#     filters=32,\n",
    "#     kernel_size=5,\n",
    "#     strides=1,\n",
    "#     padding='same',     # Padding method\n",
    "#     #data_format='channels_first',\n",
    "# ))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# # Pooling layer 1 (max pooling) output shape (32, 14, 14)\n",
    "# model.add(MaxPooling2D(\n",
    "#     pool_size=2,\n",
    "#     strides=2,\n",
    "#     padding='same',    # Padding method\n",
    "#     #data_format='channels_first',\n",
    "# ))\n",
    "\n",
    "# # Conv layer 2 output shape (64, 14, 14)\n",
    "# model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# # Pooling layer 2 (max pooling) output shape (64, 7, 7)\n",
    "# model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "\n",
    "# # Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# # Fully connected layer 2 to shape (10) for 10 classes\n",
    "# model.add(Dense(8))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# # Another way to define your optimizer\n",
    "# adam = Adam(lr=1e-4)\n",
    "\n",
    "# # We add metrics to get more results you want to see\n",
    "# model.compile(optimizer=adam,\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# print('Training ------------')\n",
    "# # Another way to train the model\n",
    "# model.fit(X_train, Y_train, epochs=1, batch_size=64,)\n",
    "\n",
    "# print('\\nTesting ------------')\n",
    "# # Evaluate the model with the metrics we defined earlier\n",
    "# loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "# print('\\ntest loss: ', loss)\n",
    "# print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce6c6e507176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "batch_size = 64\n",
    "num_classes = 8\n",
    "epochs = 1\n",
    "img_rows, img_cols = 30, 30\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(7, 7),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1256, activation='relu'))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_train, Y_train))\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(64, kernel_size=(7, 7),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='Adadelta',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_train, Y_train))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
